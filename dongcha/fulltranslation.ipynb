{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import math\n",
    "import itertools\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from Bio import pairwise2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 超参数配置\n",
    "KMER_LENGTH = 3  # 可调节的k-mer长度\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "BATCH_SIZE = 128\n",
    "D_MODEL = 128\n",
    "NHEAD = 8\n",
    "NUM_ENCODER_LAYERS = 3\n",
    "NUM_DECODER_LAYERS = 3\n",
    "CNN_OUT_CHANNELS = 64\n",
    "LEARNING_RATE = 0.001\n",
    "NUM_EPOCHS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成所有可能的k-mer组合\n",
    "BASES = ['A', 'T', 'C', 'G']\n",
    "ALL_KMERS = [''.join(p) for p in itertools.product(BASES, repeat=KMER_LENGTH)]\n",
    "\n",
    "# 构建k-mer词汇表\n",
    "vocab = {'<sos>': 0, '<eos>': 1, '<pad>': 2}\n",
    "current_idx = 3\n",
    "for kmer in ALL_KMERS:\n",
    "    vocab[kmer] = current_idx\n",
    "    current_idx += 1\n",
    "tgt_vocab_size = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 辅助函数\n",
    "def reverse_complement(s):\n",
    "    complement = {'A': 'T', 'T': 'A', 'C': 'G', 'G': 'C', 'N': 'N'}\n",
    "    return ''.join([complement.get(c, 'N') for c in reversed(s)])\n",
    "\n",
    "def remove_outliers(sequences):\n",
    "    result = []\n",
    "    for arr in sequences:\n",
    "        q1 = np.percentile(arr, 25)\n",
    "        q3 = np.percentile(arr, 75)\n",
    "        iqr = q3 - q1\n",
    "        lower_bound = q1 - 1.5 * iqr\n",
    "        upper_bound = q3 + 1.5 * iqr\n",
    "        filtered_arr = arr[(arr >= lower_bound) & (arr <= upper_bound)]\n",
    "        result.append(filtered_arr)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据加载与预处理\n",
    "data_path = './data_slice/'\n",
    "DNA_label = [\n",
    "    'TTTTTTTTTCCTTTTTTTTTTTCCCTAAACAAGAATACCACGACTAGCATTTTTCAGATCTCACTATC',\n",
    "    'AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAATTTTTTTTTTAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA',\n",
    "    'TTTTTTTTTTTTTTTGGGGGTTTTTTTTTTTTTTTAAAAATTTTTTTTTTTTTTTCCCCC',\n",
    "    'TTTTTTTTTTTTTTTTTTGGTTTTTTTTTTTTTTTTTTAATTTTTTTTTTTTTTTTTTTCC',\n",
    "    'AAAAAAAAAAAAAAAAAAGGTTTTTTTTTTTTTTTTTTGGAAAAAAAAAAAAAAAAAACC'\n",
    "]\n",
    "\n",
    "# 加载并增强训练数据\n",
    "sequences, labels = [], []\n",
    "sequences_test, labels_test = [], []\n",
    "\n",
    "for f in os.listdir(data_path):\n",
    "    path = os.path.join(data_path, f)\n",
    "    with open(path, 'rb') as file:\n",
    "        slice_data = pickle.load(file)\n",
    "        label_number = f.split('.')[0][-1]\n",
    "        \n",
    "        if label_number == '2':\n",
    "            # 测试数据不增强\n",
    "            for seq in slice_data:\n",
    "                if 10 <= len(seq) <= 5000:\n",
    "                    sequences_test.append(seq)\n",
    "                    labels_test.append(DNA_label[int(label_number)-2])\n",
    "        else:\n",
    "            # 训练数据增强\n",
    "            original_label = DNA_label[int(label_number)-2]\n",
    "            for seq in slice_data:\n",
    "                if 10 <= len(seq) <= 5000:\n",
    "                    # 原始方向\n",
    "                    sequences.append(seq)\n",
    "                    labels.append(original_label)\n",
    "                    # 反转方向\n",
    "                    reversed_seq = seq[::-1].copy()\n",
    "                    reversed_label = reverse_complement(original_label)\n",
    "                    sequences.append(reversed_seq)\n",
    "                    labels.append(reversed_label)\n",
    "\n",
    "# 数据清洗\n",
    "src_data = [seq[:MAX_SRC_LEN] for seq in remove_outliers(sequences)]\n",
    "tgt_data = labels\n",
    "src_data_test = [seq[:MAX_SRC_LEN] for seq in remove_outliers(sequences_test)]\n",
    "tgt_data_test = labels_test\n",
    "\n",
    "# 构建词汇表\n",
    "vocab = {'<sos>': 0, '<eos>': 1, '<pad>': 2}\n",
    "for seq in tgt_data + tgt_data_test:\n",
    "    for c in seq:\n",
    "        if c not in vocab:\n",
    "            vocab[c] = len(vocab)\n",
    "tgt_vocab_size = len(vocab)\n",
    "max_tgt_len = max(len(seq) for seq in tgt_data) + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TranslationDataset(Dataset):\n",
    "    def __init__(self, src_data, tgt_data):\n",
    "        self.src, self.tgt_input, self.tgt_output = [], [], []\n",
    "        \n",
    "        # 处理源数据\n",
    "        for seq in src_data:\n",
    "            seq = np.array(seq)\n",
    "            seq_mean = np.mean(seq)\n",
    "            seq_std = np.std(seq) + 1e-8\n",
    "            normalized = [(x - seq_mean)/seq_std for x in seq]\n",
    "            padded = normalized + [0]*(MAX_SRC_LEN - len(normalized))\n",
    "            self.src.append(padded[:MAX_SRC_LEN])\n",
    "        \n",
    "        # 处理目标数据\n",
    "        for seq in tgt_data:\n",
    "            indexed = [0] + [vocab[c] for c in seq] + [1]\n",
    "            input_seq = indexed[:-1] + [2]*(max_tgt_len - len(indexed) + 1)\n",
    "            output_seq = indexed[1:] + [2]*(max_tgt_len - len(indexed) + 1)\n",
    "            self.tgt_input.append(input_seq[:max_tgt_len])\n",
    "            self.tgt_output.append(output_seq[:max_tgt_len])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.src)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (\n",
    "            torch.tensor(self.src[idx], dtype=torch.float32),\n",
    "            torch.tensor(self.tgt_input[idx], dtype=torch.long),\n",
    "            torch.tensor(self.tgt_output[idx], dtype=torch.long)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型组件\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=500):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=DROPOUT)\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe.unsqueeze(1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0)]\n",
    "        return self.dropout(x)\n",
    "\n",
    "class Seq2SeqTransformer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # 双向卷积层\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.conv_fwd = nn.Sequential(\n",
    "            nn.Conv1d(1, 32, 5, padding=2),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Conv1d(32, D_MODEL//2, 3, padding=1)\n",
    "        )\n",
    "        self.conv_rev = nn.Sequential(\n",
    "            nn.Conv1d(1, 32, 5, padding=2),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Conv1d(32, D_MODEL//2, 3, padding=1)\n",
    "        )\n",
    "        self.src_proj = nn.Linear(D_MODEL, D_MODEL)\n",
    "        self.pos_encoder = PositionalEncoding(D_MODEL)\n",
    "        \n",
    "        self.transformer = nn.Transformer(\n",
    "            d_model=D_MODEL,\n",
    "            nhead=4,  # 减少注意力头数\n",
    "            num_encoder_layers=2,\n",
    "            num_decoder_layers=2,\n",
    "            dim_feedforward=256,\n",
    "            dropout=0.3\n",
    "        )\n",
    "        self.tgt_embed = nn.Embedding(tgt_vocab_size, D_MODEL)\n",
    "        self.fc_out = nn.Linear(D_MODEL, tgt_vocab_size)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        for p in self.parameters():\n",
    "            if p.dim() > 1:\n",
    "                nn.init.xavier_uniform_(p)\n",
    "\n",
    "    def forward(self, src, tgt):\n",
    "        # 源序列处理\n",
    "        src = src.unsqueeze(-1)  # [B, S, 1]\n",
    "        src = src.permute(1, 0, 2)  # [S, B, 1]\n",
    "        \n",
    "        # 双向特征提取\n",
    "        src_fwd = self.conv_fwd(src.permute(1, 2, 0)).permute(2, 0, 1)  # [S, B, D//2]\n",
    "        src_rev = self.conv_rev(torch.flip(src, [0]).permute(1, 2, 0)).permute(2, 0, 1)  # [S, B, D//2]\n",
    "        src_features = torch.cat([src_fwd, src_rev], dim=-1)  # [S, B, D]\n",
    "        \n",
    "        src_emb = self.dropout(self.src_proj(src_features))\n",
    "        src_emb = self.pos_encoder(src_emb)\n",
    "        \n",
    "        # 目标序列处理\n",
    "        tgt = tgt.permute(1, 0)  # [T, B]\n",
    "        tgt_emb = self.dropout(self.tgt_embed(tgt) * math.sqrt(D_MODEL))\n",
    "        tgt_emb = self.pos_encoder(tgt_emb)\n",
    "        \n",
    "        # 生成掩码\n",
    "        src_padding_mask = (src.squeeze(-1) == 0).transpose(0, 1)\n",
    "        tgt_padding_mask = (tgt == 2).transpose(0, 1)\n",
    "        tgt_mask = nn.Transformer.generate_square_subsequent_mask(tgt.size(0)).to(device)\n",
    "        \n",
    "        output = self.transformer(\n",
    "            src_emb, tgt_emb,\n",
    "            src_key_padding_mask=src_padding_mask,\n",
    "            tgt_key_padding_mask=tgt_padding_mask,\n",
    "            memory_key_padding_mask=src_padding_mask,\n",
    "            tgt_mask=tgt_mask\n",
    "        )\n",
    "        return self.fc_out(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化模型\n",
    "model = Seq2SeqTransformer().to(device)\n",
    "optimizer = AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=0.01)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=2)\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer, \n",
    "    num_warmup_steps=10,\n",
    "    num_training_steps=100\n",
    ")\n",
    "\n",
    "# 数据加载\n",
    "dataset = TranslationDataset(src_data, tgt_data)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, len(dataset)-train_size])\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 426/426 [00:45<00:00,  9.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model with val loss 0.3842\n",
      "Epoch 1/20\n",
      "Train Loss: 0.4353 | Val Loss: 0.3842\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 426/426 [00:44<00:00,  9.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20\n",
      "Train Loss: 0.3874 | Val Loss: 0.3842\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 426/426 [00:44<00:00,  9.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20\n",
      "Train Loss: 0.3876 | Val Loss: 0.3842\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4:   9%|▉         | 39/426 [00:04<00:40,  9.46it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[121], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m tgt_out \u001b[38;5;241m=\u001b[39m tgt_out\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     14\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 15\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt_in\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, tgt_vocab_size), tgt_out\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m     17\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[119], line 79\u001b[0m, in \u001b[0;36mSeq2SeqTransformer.forward\u001b[0;34m(self, src, tgt)\u001b[0m\n\u001b[1;32m     76\u001b[0m tgt_padding_mask \u001b[38;5;241m=\u001b[39m (tgt \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     77\u001b[0m tgt_mask \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mTransformer\u001b[38;5;241m.\u001b[39mgenerate_square_subsequent_mask(tgt\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m))\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 79\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[43m    \u001b[49m\u001b[43msrc_emb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt_emb\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[43m    \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrc_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtgt_key_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtgt_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_key_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrc_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtgt_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtgt_mask\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc_out(output)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/transformer.py:272\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[0;34m(self, src, tgt, src_mask, tgt_mask, memory_mask, src_key_padding_mask, tgt_key_padding_mask, memory_key_padding_mask, src_is_causal, tgt_is_causal, memory_is_causal)\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m src\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md_model \u001b[38;5;129;01mor\u001b[39;00m tgt\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md_model:\n\u001b[1;32m    268\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    269\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe feature number of src and tgt must be equal to d_model\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    270\u001b[0m     )\n\u001b[0;32m--> 272\u001b[0m memory \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrc_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m    \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrc_is_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    278\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder(\n\u001b[1;32m    279\u001b[0m     tgt,\n\u001b[1;32m    280\u001b[0m     memory,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    286\u001b[0m     memory_is_causal\u001b[38;5;241m=\u001b[39mmemory_is_causal,\n\u001b[1;32m    287\u001b[0m )\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/transformer.py:511\u001b[0m, in \u001b[0;36mTransformerEncoder.forward\u001b[0;34m(self, src, mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    508\u001b[0m is_causal \u001b[38;5;241m=\u001b[39m _detect_is_causal_mask(mask, is_causal, seq_len)\n\u001b[1;32m    510\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m mod \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m--> 511\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmod\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    512\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    513\u001b[0m \u001b[43m        \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    514\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    515\u001b[0m \u001b[43m        \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrc_key_padding_mask_for_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    516\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_nested:\n\u001b[1;32m    519\u001b[0m     output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mto_padded_tensor(\u001b[38;5;241m0.0\u001b[39m, src\u001b[38;5;241m.\u001b[39msize())\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/transformer.py:904\u001b[0m, in \u001b[0;36mTransformerEncoderLayer.forward\u001b[0;34m(self, src, src_mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    900\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ff_block(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(x))\n\u001b[1;32m    901\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    902\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm1(\n\u001b[1;32m    903\u001b[0m         x\n\u001b[0;32m--> 904\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sa_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    905\u001b[0m     )\n\u001b[1;32m    906\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ff_block(x))\n\u001b[1;32m    908\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/transformer.py:927\u001b[0m, in \u001b[0;36mTransformerEncoderLayer._sa_block\u001b[0;34m(self, x, attn_mask, key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    911\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_sa_block\u001b[39m(\n\u001b[1;32m    912\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    913\u001b[0m     x: Tensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    916\u001b[0m     is_causal: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    917\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m    918\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself_attn(\n\u001b[1;32m    919\u001b[0m         x,\n\u001b[1;32m    920\u001b[0m         x,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    925\u001b[0m         is_causal\u001b[38;5;241m=\u001b[39mis_causal,\n\u001b[1;32m    926\u001b[0m     )[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 927\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/dropout.py:70\u001b[0m, in \u001b[0;36mDropout.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/functional.py:1425\u001b[0m, in \u001b[0;36mdropout\u001b[0;34m(input, p, training, inplace)\u001b[0m\n\u001b[1;32m   1422\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m p \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m p \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1.0\u001b[39m:\n\u001b[1;32m   1423\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdropout probability has to be between 0 and 1, but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mp\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1424\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m-> 1425\u001b[0m     _VF\u001b[38;5;241m.\u001b[39mdropout_(\u001b[38;5;28minput\u001b[39m, p, training) \u001b[38;5;28;01mif\u001b[39;00m inplace \u001b[38;5;28;01melse\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1426\u001b[0m )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 训练循环\n",
    "best_val_loss = float('inf')\n",
    "train_losses, val_losses = [], []\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "    epoch_train_loss = 0\n",
    "    \n",
    "    for src, tgt_in, tgt_out in tqdm(train_loader, desc=f\"Epoch {epoch+1}\"):\n",
    "        src = src.to(device)\n",
    "        tgt_in = tgt_in.to(device)\n",
    "        tgt_out = tgt_out.to(device).permute(1, 0)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(src, tgt_in)\n",
    "        loss = criterion(output.view(-1, tgt_vocab_size), tgt_out.reshape(-1))\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        epoch_train_loss += loss.item()\n",
    "    \n",
    "    avg_train_loss = epoch_train_loss / len(train_loader)\n",
    "    train_losses.append(avg_train_loss)\n",
    "    \n",
    "    # 验证\n",
    "    model.eval()\n",
    "    epoch_val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for src, tgt_in, tgt_out in val_loader:\n",
    "            src = src.to(device)\n",
    "            tgt_in = tgt_in.to(device)\n",
    "            tgt_out = tgt_out.to(device).permute(1, 0)\n",
    "            \n",
    "            output = model(src, tgt_in)\n",
    "            loss = criterion(output.view(-1, tgt_vocab_size), tgt_out.reshape(-1))\n",
    "            epoch_val_loss += loss.item()\n",
    "    \n",
    "    avg_val_loss = epoch_val_loss / len(val_loader)\n",
    "    val_losses.append(avg_val_loss)\n",
    "    \n",
    "    # 保存最佳模型\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        torch.save(model.state_dict(), 'best_model.pth')\n",
    "        print(f\"Saved best model with val loss {avg_val_loss:.4f}\")\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{NUM_EPOCHS}\")\n",
    "    print(f\"Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f}\")\n",
    "    print('-'*50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 可视化训练过程\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.title('Training Progress')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.savefig('training_curve.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_613597/393175432.py:38: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('best_model.pth', map_location=device))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Seq2SeqTransformer(\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (conv_fwd): Sequential(\n",
       "    (0): Conv1d(1, 32, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): GELU(approximate='none')\n",
       "    (3): Dropout(p=0.3, inplace=False)\n",
       "    (4): Conv1d(32, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  )\n",
       "  (conv_rev): Sequential(\n",
       "    (0): Conv1d(1, 32, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): GELU(approximate='none')\n",
       "    (3): Dropout(p=0.3, inplace=False)\n",
       "    (4): Conv1d(32, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  )\n",
       "  (src_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (pos_encoder): PositionalEncoding(\n",
       "    (dropout): Dropout(p=0.3, inplace=False)\n",
       "  )\n",
       "  (transformer): Transformer(\n",
       "    (encoder): TransformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-1): 2 x TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=128, out_features=256, bias=True)\n",
       "          (dropout): Dropout(p=0.3, inplace=False)\n",
       "          (linear2): Linear(in_features=256, out_features=128, bias=True)\n",
       "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.3, inplace=False)\n",
       "          (dropout2): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): TransformerDecoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-1): 2 x TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=128, out_features=256, bias=True)\n",
       "          (dropout): Dropout(p=0.3, inplace=False)\n",
       "          (linear2): Linear(in_features=256, out_features=128, bias=True)\n",
       "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.3, inplace=False)\n",
       "          (dropout2): Dropout(p=0.3, inplace=False)\n",
       "          (dropout3): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (tgt_embed): Embedding(7, 128)\n",
       "  (fc_out): Linear(in_features=128, out_features=7, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 推理函数\n",
    "def preprocess_input(seq):\n",
    "    seq = np.array(seq[:MAX_SRC_LEN])\n",
    "    seq_mean = np.mean(seq)\n",
    "    seq_std = np.std(seq) + 1e-8\n",
    "    normalized = [(x - seq_mean)/seq_std for x in seq]\n",
    "    padded = normalized + [0]*(MAX_SRC_LEN - len(normalized))\n",
    "    return torch.tensor(padded, dtype=torch.float32).unsqueeze(0).to(device)\n",
    "\n",
    "def translate_once(model, src_seq, max_length=200):\n",
    "    src_tensor = preprocess_input(src_seq)\n",
    "    tgt_tokens = [vocab['<sos>']]\n",
    "    total_prob = 0.0\n",
    "    \n",
    "    for _ in range(max_length):\n",
    "        tgt_tensor = torch.tensor(tgt_tokens, dtype=torch.long).unsqueeze(0).to(device)\n",
    "        with torch.no_grad():\n",
    "            output = model(src_tensor, tgt_tensor)\n",
    "        \n",
    "        probs = F.softmax(output[-1], dim=-1)\n",
    "        next_token = probs.argmax().item()\n",
    "        total_prob += probs.max().item()\n",
    "        \n",
    "        if next_token == vocab['<eos>']:\n",
    "            break\n",
    "        tgt_tokens.append(next_token)\n",
    "    \n",
    "    idx_to_char = {v:k for k,v in vocab.items()}\n",
    "    decoded = [idx_to_char[idx] for idx in tgt_tokens[1:]]\n",
    "    return ''.join(decoded), total_prob/len(tgt_tokens)\n",
    "\n",
    "def full_translate(model, src_seq, max_length=200):\n",
    "    pred_fwd, prob_fwd = translate_once(model, src_seq, max_length)\n",
    "    pred_rev, prob_rev = translate_once(model, src_seq[::-1], max_length)\n",
    "    return pred_fwd if prob_fwd >= prob_rev else reverse_complement(pred_rev)\n",
    "\n",
    "# 加载最佳模型\n",
    "model.load_state_dict(torch.load('best_model.pth', map_location=device))\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 100/100 [02:05<00:00,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Similarity on Test Set: 15.06%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 评估函数\n",
    "def evaluate(model, test_src, test_tgt, num_samples=100):\n",
    "    indices = np.random.choice(len(test_src), min(num_samples, len(test_src)), replace=False)\n",
    "    total_similarity = 0.0\n",
    "    \n",
    "    for idx in tqdm(indices, desc=\"Evaluating\"):\n",
    "        src_seq = test_src[idx]\n",
    "        true_label = test_tgt[idx]\n",
    "        \n",
    "        # 双向预测\n",
    "        pred_seq = full_translate(model, src_seq)\n",
    "        \n",
    "        # 序列比对\n",
    "        alignments = pairwise2.align.globalms(\n",
    "            true_label, pred_seq, 1, 0, -0.1, -0.1\n",
    "        )\n",
    "        \n",
    "        if alignments:\n",
    "            best_aln = alignments[0]\n",
    "            matches = sum(a == b for a,b in zip(best_aln.seqA, best_aln.seqB))\n",
    "            similarity = matches / len(true_label) * 100\n",
    "            total_similarity += similarity\n",
    "    \n",
    "    return total_similarity / len(indices)\n",
    "\n",
    "# 运行评估\n",
    "test_score = evaluate(model, src_data_test, tgt_data_test)\n",
    "print(f\"\\nAverage Similarity on Test Set: {test_score:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translated: GGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGG\n",
      "Original: TTTTTTTTTCCTTTTTTTTTTTCCCTAAACAAGAATACCACGACTAGCATTTTTCAGATCTCACTATC\n",
      "Similarity: 5.88%\n"
     ]
    }
   ],
   "source": [
    "# 测试样例\n",
    "import random\n",
    "rd = random.randint(0, len(src_data_test)-1)\n",
    "sample = src_data_test[rd]\n",
    "label = tgt_data_test[rd]\n",
    "# 使用模型进行翻译 \n",
    "translated = full_translate(model, sample)\n",
    "# 全局比对（Needleman-Wunsch算法，匹配=1，不匹配/gap=0）\n",
    "alignments = pairwise2.align.globalms(\n",
    "    label, translated, 1, 0, -0.1, -0.1\n",
    ")\n",
    "\n",
    "if alignments:\n",
    "    best_alignment = alignments[0]\n",
    "    aligned_label = best_alignment.seqA  \n",
    "    aligned_pred = best_alignment.seqB   \n",
    "    matches = sum(a == b for a, b in zip(aligned_label, aligned_pred))\n",
    "    label_len = len(label)  # 原始标签长度\n",
    "    similarity = (matches / label_len) * 100 if label_len > 0 else 0\n",
    "print(f'Translated: {translated}')\n",
    "print(f'Original: {label}')\n",
    "print(f'Similarity: {similarity:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
