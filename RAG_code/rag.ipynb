{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:成功读取工作表: 质控规则, 共 316 行\n",
      "INFO:__main__:成功读取工作表: 质控问题, 共 144 行\n",
      "INFO:__main__:成功读取工作表: 记录单名称, 共 42 行\n",
      "INFO:__main__:共生成 502 个文档\n",
      "INFO:__main__:成功读取工作表: 时效性, 共 6 行\n",
      "INFO:__main__:成功读取工作表: 完整性, 共 130 行\n",
      "INFO:__main__:成功读取工作表: 合理性-互补词, 共 65 行\n",
      "INFO:__main__:成功读取工作表: 环节质控检查项, 共 314 行\n",
      "INFO:__main__:共生成 515 个文档\n",
      "/tmp/ipykernel_3736770/4058557662.py:202: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(\n",
      "INFO:datasets:PyTorch version 2.5.1+cu121 available.\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: ./models/text2vec-base-chinese\n",
      "INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import logging\n",
    "from typing import List, Dict, Any\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# 配置日志\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def build_document(\n",
    "    row: pd.Series,\n",
    "    sheet_name: str,\n",
    "    filename: str,\n",
    "    content_fields: List[str],\n",
    "    metadata_fields: Dict[str, str]\n",
    ") -> Document:\n",
    "    \"\"\"通用文档构建函数\n",
    "    \n",
    "    Args:\n",
    "        row: 数据行\n",
    "        sheet_name: 工作表名称\n",
    "        filename: 文件名\n",
    "        content_fields: 需要放入page_content的字段列表\n",
    "        metadata_fields: 元数据字段映射 {元数据键名: 数据列名}\n",
    "    \n",
    "    Returns:\n",
    "        LangChain Document对象\n",
    "    \"\"\"\n",
    "    # 构建元数据\n",
    "    metadata = {\"来源表格\": f\"{filename}，{sheet_name}\"}\n",
    "    for meta_key, col_name in metadata_fields.items():\n",
    "        metadata[meta_key] = str(row[col_name])  # 确保所有值为字符串\n",
    "    \n",
    "    # 构建内容\n",
    "    content_parts = []\n",
    "    for field in content_fields:\n",
    "        content_parts.append(f\"{field}：{str(row[field])}\")\n",
    "    \n",
    "    return Document(\n",
    "        page_content=\"\\n\".join(content_parts),\n",
    "        metadata=metadata\n",
    "    )\n",
    "\n",
    "def validate_dataframe(df: pd.DataFrame, required_columns: List[str], sheet_name: str) -> None:\n",
    "    \"\"\"验证DataFrame是否包含必需列\"\"\"\n",
    "    missing_cols = set(required_columns) - set(df.columns)\n",
    "    if missing_cols:\n",
    "        raise ValueError(\n",
    "            f\"工作表 '{sheet_name}' 缺少必要列: {missing_cols}\\n\"\n",
    "            f\"现有列: {list(df.columns)}\"\n",
    "        )\n",
    "\n",
    "def process_excel_to_rag(sheet_configs:dict,file_path: str) -> List[Document]:\n",
    "    \"\"\"处理Excel文件生成RAG文档\n",
    "    \n",
    "    Args:\n",
    "        file_path: Excel文件路径\n",
    "    \n",
    "    Returns:\n",
    "        包含所有文档的列表\n",
    "    \"\"\"\n",
    "    # 获取基础文件名（不带路径）\n",
    "    filename = os.path.basename(file_path)\n",
    "    documents = []\n",
    "    # 处理每个工作表\n",
    "    for sheet_name, config in sheet_configs.items():\n",
    "        try:\n",
    "            # 读取数据\n",
    "            df = pd.read_excel(file_path, sheet_name=sheet_name)\n",
    "            logger.info(f\"成功读取工作表: {sheet_name}, 共 {len(df)} 行\")\n",
    "            \n",
    "            # 数据验证\n",
    "            validate_dataframe(df, config['required_columns'], sheet_name)\n",
    "            \n",
    "            # 处理每一行\n",
    "            for _, row in df.iterrows():\n",
    "                # 跳过关键字段为空的行\n",
    "                #if pd.isnull(row['病历']):\n",
    "                    #logger.warning(f\"跳过空病历记录（工作表 {sheet_name}）\")\n",
    "                    #continue\n",
    "                \n",
    "                # 构建文档\n",
    "                doc = build_document(\n",
    "                    row=row,\n",
    "                    sheet_name=sheet_name,\n",
    "                    filename=filename,\n",
    "                    content_fields=config['content_fields'],\n",
    "                    metadata_fields=config['metadata_fields']\n",
    "                )\n",
    "                documents.append(doc)\n",
    "                \n",
    "        except Exception as e:\n",
    "            logger.error(f\"处理工作表 {sheet_name} 时出错: {str(e)}\")\n",
    "            raise\n",
    "    \n",
    "    logger.info(f\"共生成 {len(documents)} 个文档\")\n",
    "    return documents\n",
    "excel_path_0 = \"A-2-5_模型喂养数据-护理病历质控规则.xlsx\"\n",
    "sheet_configs_0 = {\n",
    "    '汇总': {\n",
    "        'required_columns': ['性别','年龄','入院诊断','体征单诊断','病历','检查项目','备注','问题控件'],\n",
    "        'content_fields': ['性别','年龄','入院诊断','体征单诊断','病历','检查项目','备注','问题控件'],\n",
    "        'metadata_fields': {'性别': '性别', '年龄': '年龄', '入院诊断': '入院诊断', '体征单诊断': '体征单诊断', '病历': '病历', '检查项目': '检查项目', '备注': '备注', '问题控件': '问题控件'}\n",
    "    }\n",
    "}\n",
    "\n",
    "excel_path_1 = \"A-2-5-1_模型喂养数据-护理病历质控规则-文字版.xlsx\"\n",
    "sheet_configs_1 = {\n",
    "    '质控规则': {\n",
    "        'required_columns': ['项目', '项目检查内容释义','二级标题','三级标题'],\n",
    "        'content_fields': ['项目', '项目检查内容释义','二级标题','三级标题'],\n",
    "        'metadata_fields': {'项目': '项目', '项目检查内容释义': '项目检查内容释义', '二级标题': '二级标题', '三级标题': '三级标题'}\n",
    "    },\n",
    "    '质控问题': {\n",
    "        'required_columns': ['质控问题'],\n",
    "        'content_fields': ['质控问题'],\n",
    "        'metadata_fields': {'质控问题': '质控问题'}\n",
    "    },\n",
    "    '记录单名称': {\n",
    "        'required_columns': ['病历名称'],\n",
    "        'content_fields': ['病历名称'],\n",
    "        'metadata_fields': {\n",
    "            '病历名称': '病历名称'\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "excel_path_2 = \"A-2-5-2_模型喂养数据-护理病历质控规则-数据库配置版.xlsx\"\n",
    "sheet_configs_2 = {\n",
    "    '时效性': {\n",
    "        'required_columns': ['病历', '完成时间'],\n",
    "        'content_fields': ['病历', '完成时间'],\n",
    "        'metadata_fields': {'病历类型': '病历', '完成时间': '完成时间'}\n",
    "    },\n",
    "    '完整性': {\n",
    "        'required_columns': ['病历', '必填项'],\n",
    "        'content_fields': ['病历', '必填项'],\n",
    "        'metadata_fields': {'病历类型': '病历', '必填项': '必填项'}\n",
    "    },\n",
    "    '合理性-互补词': {\n",
    "        'required_columns': ['病历', '互补词条件', '互补控件'],\n",
    "        'content_fields': ['病历', '互补词条件', '互补控件'],\n",
    "        'metadata_fields': {\n",
    "            '病历类型': '病历', \n",
    "            '互补词条件': '互补词条件',\n",
    "            '互补控件': '互补控件'\n",
    "        }\n",
    "    },\n",
    "    '环节质控检查项': {\n",
    "        'required_columns': ['病历', '环节点', '分类', '检查项'],\n",
    "        'content_fields': ['病历', '环节点', '分类', '检查项'],\n",
    "        'metadata_fields': {\n",
    "            '病历类型': '病历',\n",
    "            '环节节点': '环节点',\n",
    "            '分类': '分类',\n",
    "            '检查项': '检查项'\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "try:\n",
    "    #rag_docs_0 = process_excel_to_rag(sheet_configs_0,excel_path_0)\n",
    "    rag_docs_1 = process_excel_to_rag(sheet_configs_1,excel_path_1)\n",
    "    rag_docs_2 = process_excel_to_rag(sheet_configs_2,excel_path_2)\n",
    "except Exception as e:\n",
    "    logger.error(f\"处理Excel文件失败: {str(e)}\")\n",
    "    raise\n",
    "from typing import List, Any\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma  # 改为导入Chroma\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "def vectorize_documents(\n",
    "    all_docs: List[List[Document]],  # 接收二维文档列表\n",
    "    embedding_model: str = \"local\",\n",
    "    vector_db: str = \"chroma\",\n",
    "    chunk_size: int = 1000,\n",
    "    chunk_overlap: int = 200\n",
    ") -> Any:\n",
    "    \n",
    "    # 展平嵌套文档列表\n",
    "    combined_docs = [doc for sublist in all_docs for doc in sublist]\n",
    "    \n",
    "    # 文档结构验证\n",
    "    for i, doc in enumerate(combined_docs):\n",
    "        if not isinstance(doc, Document):\n",
    "            raise TypeError(f\"第 {i} 个元素不是Document对象，实际类型：{type(doc)}\")\n",
    "        if not hasattr(doc, \"page_content\"):\n",
    "            raise AttributeError(f\"第 {i} 个Document缺少page_content属性\")\n",
    "\n",
    "    # 文本分割\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        length_function=len\n",
    "    )\n",
    "    splits = text_splitter.split_documents(combined_docs)\n",
    "\n",
    "    # 本地模型加载（适配您的目录结构）\n",
    "    embeddings = HuggingFaceEmbeddings(\n",
    "        model_name=\"./models/text2vec-base-chinese\",\n",
    "        model_kwargs={'device': 'cuda'},  \n",
    "        encode_kwargs={'normalize_embeddings': True}\n",
    "    )\n",
    "    \n",
    "    # 创建向量库\n",
    "    return Chroma.from_documents(splits, embeddings)\n",
    "\n",
    "# 创建向量库\n",
    "vector_store = vectorize_documents(\n",
    "    all_docs=[rag_docs_1, rag_docs_2],\n",
    "    embedding_model=\"local\",  # 切换模型时修改此参数\n",
    "    vector_db=\"chroma\",\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#召回测试\n",
    "test_queries = [\"护理记录单\", \"入院评估单\"]\n",
    "\n",
    "for query in test_queries:\n",
    "    print(f\"\\n测试查询：'{query}'\")\n",
    "    results = vector_store.similarity_search_with_score(query, k=10)\n",
    "    \n",
    "    for i, (doc, score) in enumerate(results):\n",
    "        print(f\"结果 {i+1} (相似度得分：{score:.3f}):\")\n",
    "        print(doc.page_content[:200] + \"...\")\n",
    "        print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "\n",
    "# 配置DeepSeek API参数\n",
    "os.environ[\"DEEPSEEK_API_KEY\"] = \"sk-19af4c75b5ba4ddaa864f7328a5e1073\"\n",
    "\n",
    "# 创建Chat模型实例\n",
    "llm = ChatOpenAI(\n",
    "    model=\"deepseek-chat\",\n",
    "    temperature=0.7,\n",
    "    max_tokens=1024,\n",
    "    openai_api_key=os.getenv(\"DEEPSEEK_API_KEY\"),\n",
    "    base_url=\"https://api.deepseek.com/v1\"  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.deepseek.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "结构化结果：\n",
      "问题1：入院评估单缺少多项必填项（如科室、就诊医院、病历名称、住院号、ID号等基础信息及各项评估分值）   依据规则：[必填项：科室,就诊医院,病历名称,住院号,姓名,性别,年龄,ID号,焦虑,焦虑自评量表分值...（共61项）]（来源：[A-2-5-2_模型喂养数据-护理病历质控规则-数据库配置版.xlsx，完整性]）\n",
      "问题2：入院评估单未记录患者生命体征数据（体温、脉搏、呼吸、血压等）   依据规则：[必填项包含体温(℃)、脉搏(次/min)、呼吸(次/min)、收缩压(mmHg)、舒张压(mmHg)]（来源：[同规则表格中患者转运交接记录单>=3岁必填项]）\n",
      "问题3：未完成专科评估（压力性损伤、跌倒/坠床等）   依据规则：[必填项包含压力性损伤评估（Braden）总分,跌倒/坠床评估总分等专科评分]（来源：[入院评估单大于3岁必填项]）\n",
      "问题4：缺少中医特色评估内容（舌象、脉象等）   依据规则：[必填项包含舌质,舌苔,切脉等中医项目]（来源：[同入院评估单规则]）\n",
      "问题5：未记录患者基础生理参数（身高、体重）   依据规则：[必填项包含身高(cm),体重(kg)]（来源：[同入院评估单规则]）  注：由于待检查病历仅提供片段信息，实际缺失项可能更多。建议对照完整规则逐项核查61项必填内容，尤其注意评估类项目的分值和签名、记录时间等关键要素。\n",
      "\n",
      "完整分析报告：\n",
      "根据提供的病历质控规则和待检查病历，分析如下：\n",
      "\n",
      "- 问题1：入院评估单缺少多项必填项（如科室、就诊医院、病历名称、住院号、ID号等基础信息及各项评估分值）  \n",
      "依据规则：[必填项：科室,就诊医院,病历名称,住院号,姓名,性别,年龄,ID号,焦虑,焦虑自评量表分值...（共61项）]（来源：[A-2-5-2_模型喂养数据-护理病历质控规则-数据库配置版.xlsx，完整性]）\n",
      "\n",
      "- 问题2：入院评估单未记录患者生命体征数据（体温、脉搏、呼吸、血压等）  \n",
      "依据规则：[必填项包含体温(℃)、脉搏(次/min)、呼吸(次/min)、收缩压(mmHg)、舒张压(mmHg)]（来源：[同规则表格中患者转运交接记录单>=3岁必填项]）\n",
      "\n",
      "- 问题3：未完成专科评估（压力性损伤、跌倒/坠床等）  \n",
      "依据规则：[必填项包含压力性损伤评估（Braden）总分,跌倒/坠床评估总分等专科评分]（来源：[入院评估单大于3岁必填项]）\n",
      "\n",
      "- 问题4：缺少中医特色评估内容（舌象、脉象等）  \n",
      "依据规则：[必填项包含舌质,舌苔,切脉等中医项目]（来源：[同入院评估单规则]）\n",
      "\n",
      "- 问题5：未记录患者基础生理参数（身高、体重）  \n",
      "依据规则：[必填项包含身高(cm),体重(kg)]（来源：[同入院评估单规则]）\n",
      "\n",
      "注：由于待检查病历仅提供片段信息，实际缺失项可能更多。建议对照完整规则逐项核查61项必填内容，尤其注意评估类项目的分值和签名、记录时间等关键要素。\n"
     ]
    }
   ],
   "source": [
    "# 新增依赖\n",
    "from typing import Tuple, List\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# 1. 构建检索增强生成（RAG）系统\n",
    "def create_qa_chain(vector_store, llm):\n",
    "    # 中文提示模板\n",
    "    prompt_template = \"\"\"根据以下病历质控规则和患者病历，严格按以下要求进行分析：\n",
    "    1. 逐条列出所有发现的质控问题\n",
    "    2. 每个问题必须包含规则依据（引用具体规则内容）\n",
    "    3. 输出格式：\n",
    "    - 问题1：...[问题描述]\n",
    "      依据规则：[规则内容]（来源：[来源表格]）\n",
    "    - 问题2：...\n",
    "    \n",
    "    质控规则：\n",
    "    {context}\n",
    "    \n",
    "    待检查病历：\n",
    "    {question}\n",
    "    \n",
    "    请使用中文输出，确保分析专业严谨。\"\"\"\n",
    "    \n",
    "    # 创建提示模板\n",
    "    custom_prompt = PromptTemplate(\n",
    "        template=prompt_template,\n",
    "        input_variables=[\"context\", \"question\"]\n",
    "    )\n",
    "    \n",
    "    # 构建检索链\n",
    "    return (\n",
    "        {\"context\": vector_store.as_retriever(search_kwargs={\"k\": 5}),  # 检索前5条相关规则\n",
    "         \"question\": RunnablePassthrough()}\n",
    "        | custom_prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "\n",
    "# 2. 初始化QA链\n",
    "qa_chain = create_qa_chain(vector_store, llm)\n",
    "\n",
    "# 3. 定义病历处理函数\n",
    "def analyze_medical_record(record: str) -> Tuple[List[str], str]:\n",
    "    \"\"\"\n",
    "    分析病历并返回结构化和原始结果\n",
    "    \n",
    "    :param record: 输入病历文本\n",
    "    :return: (问题列表, 完整分析报告)\n",
    "    \"\"\"\n",
    "    # 执行分析\n",
    "    analysis = qa_chain.invoke(record)\n",
    "    \n",
    "    # 后处理提取问题列表\n",
    "    problem_list = []\n",
    "    current_problem = \"\"\n",
    "    for line in analysis.split('\\n'):\n",
    "        if line.startswith('- 问题'):\n",
    "            if current_problem:\n",
    "                problem_list.append(current_problem.strip())\n",
    "            current_problem = line[2:]  # 去除前缀\n",
    "        elif line.startswith('  依据规则'):\n",
    "            current_problem += \"\\n\" + line.strip()\n",
    "        elif current_problem:\n",
    "            current_problem += \" \" + line.strip()\n",
    "    \n",
    "    if current_problem:\n",
    "        problem_list.append(current_problem.strip())\n",
    "    \n",
    "    return problem_list, analysis\n",
    "\n",
    "test_record = \"\"\"\n",
    "    入院评估单\n",
    "患者：张三，男，68岁，入院时间：2024-02-20 12：00\n",
    "记录时间：23：00\n",
    "主诉：持续性胸痛3小时，伴冷汗\n",
    "入院诊断：急性前壁心肌梗死\n",
    "    \"\"\"\n",
    "    \n",
    "# 执行分析\n",
    "problems, raw = analyze_medical_record(test_record)\n",
    "\n",
    "# 打印结构化结果\n",
    "print(\"\\n结构化结果：\")\n",
    "for i, problem in enumerate(problems):\n",
    "    print(f\"{problem}\")\n",
    "print(\"\\n完整分析报告：\")\n",
    "print(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
